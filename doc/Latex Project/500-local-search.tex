\chapter{Proposed Approach: Local Search}
\label{chap:LocalSearch}
\thispagestyle{plain}

The proposed solution consists on the use of a local search meta-heuristic(s) in order to improve the solution given by the \gls{gc} heuristic. This approach uses \gls{sa}, based on M\"{u}ller's approach \cite{Mueller2009}, followed by the use of \gls{hc}. The use of \gls{hc} is justified by the fact that \gls{sa} does not guarantee a good control of the execution time, and so the parameters are given to make it almost use all the available time, which is, as mentioned in the previous chapter, 221 seconds. The rest of the optimization is carried out by \gls{hc}, whose execution time is perfectly controllable.

\section{Simulated Annealing}
\label{sec:SimulatedAnnealing}

\gls{sa} is a single-solution meta-heuristic (section \ref{subsec:MetaHeuristics}). This meta-heuristic optimizes a solution by generating neighbor solutions which might be accepted, given an acceptance criterion. A neighbor solution is obtained by applying a movement operator (also known as neighbor operator) to the current solution, creating a new solution which is a neighbor of the current one. A neighbor operator, in this context, could be the movement of an examination to another time slot. Being a single-solution meta-heuristic, it generates a single neighbor. The neighbor operators and the acceptance criterion are the most important parts of this algorithm. Changes on one of these, may get the algorithm to behave in very different ways and end up with quite different solutions.\\
\\
The acceptance criterion will, considering the current and a neighbor solution, give the percentage of acceptance of the neighbor solution. Most of the approaches using this heuristic accept a new neighbor solution if it is \textit{better} than the current one. Otherwise, there's a chance that the neighbor solution is still accepted, depending on certain parameters. These parameters are the \textit{Temperature} (normally given as maximum and minimum temperature) and the \textit{Cooling Schedule}. By definition, the higher the temperature, the higher is the chance to accept a worse solution over the current solution. The cooling schedule, as the name suggests, is a function that lowers the temperature at a given rate. The SA algorithm finishes when the current temperature is lower or equal to the minimum temperature. The temperature should start high enough in order to be able to escape from local optima, by accepting worse solutions found during the trajectory.

\subsection{Implementation}

The \gls{sa} was implemented in a way that it is independent from the type of the cooling schedule and neighbor generator. The \verb+SimulatedAnnealing+ class is abstract and implements everything except for the neighbor generator, which is an abstract method that must be implemented in order to decide how the neighbor generator behaves. It also does not implement the evaluation function (the one that computes the fitness value of a solution or neighbor). The \verb+SimulatedAnnealingTimetable+ implements the \verb+SimulatedAnnealing+ abstract class, which implements the neighbor generator method and the evaluation function attribute. The \verb+SimulatedAnnealing+ and \verb+SimulatedAnnealingTimetable+'s methods and attributes can be seen in Figure \ref{fig:SimulatedAnnealing}.\\
\\
\begin{figure}[p]
\centering
\begin{tikzpicture}
\begin{umlpackage}[x = 2, y = 0]{Heuristics Layer} 
\umlabstract[x = 0]{SimulatedAnnealing}
{
	\umlvirt{\#evaluation\_function : IEvaluationFunction}\\
	-cooling\_schedule : ICoolingSchedule
}
{
	+Exec(solution : ISolution, TMax : double, TMin : double, loops : int, \\ type : int, minimize : bool, time\_limit : long) : ISolution\\
	+Exec2(solution : ISolution, TMax : double, TMin : double, loops : int, \\ rate : double, type : int, minimize : bool, time\_limit : long) : ISolution\\
	+ExecLinearTimer(solution : ISolution, TMax : double, TMin : double, \\ milliseconds : long, type : int, minimize : bool) : ISolution\\
	+GetSANumberEvaluations(Tmax : double, R : double, K : double, \\ TMin : double) : long\\
	\umlvirt{\#GenerateNeighbor(solution : ISolution, type : int) : INeighbor}\\
	\umlvirt{\#InitVals(type : int) : void}
}
\umlclass[x = 0, y = -9]{SimulatedAnnealingTimetable}
{
	\#evaluation\_function : IEvaluationFunction\\
	-neighbor\_selection\_timetable : NeighborSelectionTimetable\\
	+\umlstatic{type\_random : int}\\
	+\umlstatic{type\_guided1 : int}\\
	+\umlstatic{type\_guided2 : int}\\
	-room\_change : int\\
	-period\_change : int\\
	-period\_room\_change : int\\
	-room\_swap : int\\
	-period\_swap : int\\
	-period\_room\_swap : int\\
	+generated\_neighbors : int\\
	-random : Random\\
	-total\_neighbor\_operators : int
}
{
	\#GenerateNeighbor(solution : ISolution, type : int) : INeighbor\\
	\#GenerateNeighbor(solution : Solution, type : int) : INeighbor\\
	-GenerateRandomNeighbor(solution : Solution) : INeighbor\\
	-GenerateGuidedNeighbor1(solution : Solution) : INeighbor\\
	-GenerateGuidedNeighbor2(solution : Solution) : INeighbor\\
	\#InitVals(type : int) : void\\
	+EstimateTotalNumberOfNeighbors(average\_reps : int, \\ total\_time : int, solution : Solution) : long
}
\end{umlpackage}


\umlimpl[anchors=90 and -90]{SimulatedAnnealingTimetable}{SimulatedAnnealing} 
\end{tikzpicture}

\caption{Simulated Annealing classes} 
\label{fig:SimulatedAnnealing}
\end{figure}
The \verb+SimulatedAnnealing+ abstract class has the methods \verb+Exec+, \verb+Exec2+, and \verb+ExecLinearTimer+, which are all similar, but were created to test different approaches. All these methods share the same code, with the exception of the cooling schedule (the way the temperature is updated) and acceptance criterion. The pseudo code for \gls{sa} can be seen in Algorithm \ref{alg:SimulatedAnnealing}.\\
\\
The \verb+ExecLinearTimer+ has a linear cooling schedule, which is proportional to the running time, and uses the acceptance criterion
\begin{equation}
P(\delta E, T) = e^{\frac{-\delta E}{T}},
\end{equation} with T being the current temperature and $\delta$E the fitness difference between the new neighbor and current solution.\\
\\
The \verb+Exec+ method shares the same acceptance criterion but uses a geometric cooling schedule \begin{equation}
T (i+1) = T(i).r,
\end{equation}with r being the temperature decreasing rate (0 < r < 1). In the geometric cooling schedule, the closer the rate is to unity, the longer the algorithm takes to finish and wider is the area of solutions to be analyzed in the solution space.\\
\\
The \verb+Exec2+ method is the one used in this project. It uses an exponential (decreasing) cooling schedule \cite{CarvalhoLisbonNovember2004}\\
\begin{equation} 
T = T_{max}e^{-r.t},
\end{equation}
where t is the current span (counter initiated at 0), T\textsubscript{max} the maximum/initial temperature, and r the decreasing rate.\\
\\
This method also uses a different acceptance criterion \begin{equation} P(\delta E, T, f(s)) = e^{\frac{-\delta E}{T.f(s)}},
\end{equation}
being $\delta$E the fitness difference between the new neighbor and current solution, T the current temperature, and f(s) the solution fitness.
\\
\begin{algorithm}[t]
\textbf{Input:} 
\begin{itemize}
	\setlength{\itemsep}{1pt}
	\item $s$ \Comment{Initial solution}
	\item $TMax$ \Comment{Maximum temperature}
	\item $TMin$ \Comment{Minimum temperature}
	\item $loops$ \Comment{Number of loops per temperature}
\end{itemize}
\begin{algorithmic}
\State $T = Tmax$ ; \Comment{Starting temperature}
\State $Ac = AcInit()$ ; \Comment{Acceptance criterion initializer}
\Repeat
	\Repeat	
		\State Generate a random neighbor $s'$;
		\State $\delta E$ = $f(s') - f(s)$ ;
		\State \textbf{If} $\delta E \leq 0$ \textbf{Then} $s = s'$ \Comment{Accept the neighbor solution}
		\State \textbf{Else} Accept $s'$ with a probability computed using the $Ac$;
	\Until Number of iterations reach $loops$
	\State $T = g(T )$ \Comment{Temperature update}
\Until $T < TMin$
\State \textbf{Output:} $s$ \Comment{return the current (best) solution}
\end{algorithmic}
\caption{Simulated Annealing method.}
\label{alg:SimulatedAnnealing}
\end{algorithm}

\subsection{Variable Rate Computation}

As mentioned previously in Section \ref{sec:SolutionInitResults}, according to the \gls{itc2007} rules, the allowed time considering the used computer is 221000 milliseconds. As this time limit is the only imposition, it was decided to implement a \gls{sa} with an adaptive cooling schedule, in order to use all the available time for the optimization process independently of the chosen dataset. This approach contrasts with the one in which a fixed cooling schedule is used. Each set has its own characteristics and using a given set of parameters for one set does not guarantee that the results will be equivalently good for the other sets. For example, suppose that we've determined the best parameters for the first set, considering a time limit of 200000 milliseconds. Running the algorithm using the same parameters for the remaining sets will not terminate on the time limit of 200000 milliseconds: the sets with less number of resources (exams, rooms, students) will be optimized using less time; on the other way, the largest datasets will demand more time, eventually running over the imposed time limit.\\
\\
Hence, a SA with a variable rate was implemented to make this heuristic run closer to the given time limit for all the datasets. Considering it is not certain that the algorithm will run within the given 221000 milliseconds, because of its stochastic nature, a time limit was added to this meta-heuristic as well, ending this heuristic automatically if the time limit is reached. To avoid the performance degradation incurred by the algorithm's halting before reaching the end of the optimization, a time offset was imposed. This offset is a percentage of the total allowed algorithm execution time. For example, instead of letting the heuristic run for 221000 milliseconds, one allows it to run for 185640 milliseconds, to have a safety margin. The offset used is 16\%.\\
\\
In order to determine the proper cooling schedule, the algorithm starts by simulating the execution of this heuristic, by running all the neighbor operators $AverageReps$ times, which in this approach, the $AverageReps$ used is 50. Using the elapsed time and the given time limit, we estimate the number of neighbors that would be generated if this heuristic was to be run within the time limit. In order to compute the number of total neighbors, we use the expression 
\begin{equation} 
CompNeighbs = TotalTime / CompTime * AverageReps * TotalOperats,
\end{equation} being $TotalTime$ the time limit (221000 milliseconds), $CompTime$ the elapsed time used in the simulation, $AverageReps$ the number of loops that all the neighbors must run (50 runs), and $TotalOperats$ the total number of used operators (5 operators). After that, we compute the exact number of the neighbors ($TotalNeighbs$) that will be generated for the given parameters, using the default rate. This is achieved by simulating this heuristic using those parameters, cooling the current temperature until it reaches the minimum and returning the number of desired generated neighbors. If the $TotalNeighbs$ is above the $CompNeighbs$, a lower rate will be used to make another simulation, until the $TotalNeighbs$ for the given rate reaches a value that is close to the $TotalNeighbs$. The pseudo code of this method can be seen in Algorithm \ref{alg:RateComputing}.\\
\\
\begin{algorithm}[t!]
\textbf{Input:} 
\begin{itemize}
	\setlength{\itemsep}{1pt}
	\item $s$ \Comment{Solution}
	\item $TMax$ \Comment{Maximum temperature}
	\item $TMin$ \Comment{Minimum temperature}
	\item $reps$ \Comment{Number of loops per temperature}
	\item $exec\_time$ \Comment{Execution time limit}
\end{itemize}
\begin{algorithmic}
\State $sa = SAInit()$ ;
\State $n = 50$ ; \Comment{Number of times each operator runs}
\State $comp\_neighbors = sa.EstimateNumberNeighbors(n, exec\_time, s)$ ;
\State $rate = 1.50^{-02}$ ;\Comment{Initial default rate}
\State $power = -3$ ;
\State $rate\_to\_sub = 10^{power}$ ;\Comment{Rate decrementing}
\State $total\_neighbors = sa.GetNumberNeighbors(TMax, rate, reps, TMin)$ ;
\Repeat	
	\State \textbf{If} $rate - rate\_to\_sub \leq 0$ \textbf{Then} $power = power - 1$ ; $rate\_to\_sub = 10^{power}$ ;
	\State $rate = rate - rate\_to\_sub$ ;
	\State $total\_neighbors = sa.GetNumberNeighbors(TMax, rate, reps, TMin)$ ;
\Until $total\_neighbors < comp\_neighbors$
\State $rate = rate + rate\_to\_sub$ ; \Comment{To guarantee that total\_neighbors < comp\_neighbors}
\State \textbf{Output:} $rate$ \Comment{Return computed rate}
\end{algorithmic}
\caption{Rate computing.}
\label{alg:RateComputing}
\end{algorithm}Some testings were made in order to check this heuristic's behavior, using the following parameters: \textit{TMax} = 0.1, \textit{TMin} = $1e-06$, \textit{loops} = 5, \textit{exec\_time} = 50000, and the computed\_rate = 0.00016. As can be seen in Figure \ref{fig:SimulatedAnnealingPlot}, it starts by accepting all worse and better neighbor solutions. In the end, the temperature is so low that it becomes harder to accept worse solutions, ending up acting similar to the \gls{hc} procedure. The axis of abscissas represents the indexes of the generated neighbors and the axis of ordinates represents the current solution's score.\\
\\
\begin{figure}[!t]
\centering

\begin{tikzpicture}
\begin{axis}[
    title={},
    xlabel={Neighbor index},
    ylabel={Solution score},
    mark size=0.2pt
]

\addplot plot file [
    color=blue,
    mark=*,
    mark options={solid},
   	smooth
    ] {sa_plot_data.dat};

\end{axis}
\end{tikzpicture}

\caption{Simulated Annealing results} 
\label{fig:SimulatedAnnealingPlot}
\end{figure}

\section{Hill Climbing}
\label{sec:HillClimbing}

\gls{hc} is a meta-heuristic different from the \gls{sa} family of meta-heuristics, in the sense that it only accepts better solutions. So, as long as it reaches a local optimum, it can't get out of that point because each neighbor solution is worse. In this way, \gls{hc} only has one parameter that is the number of iterations or time limit, which controls the algorithm's execution time.\\
\\
In the evaluation undertaken, the best results were obtained with the \verb+Exec2+ version of \gls{sa}. \gls{sa} was parametrized in order to finish execution within the specified time limit imposed by the \gls{itc2007} rules. \gls{hc} is executed after \gls{sa}, using the remaining time, until the time limit is reached.

\subsection{Implementation}
The implementation of this heuristic is very similar to that of the \gls{sa}; it contains the classes \verb+HillClimbing+ and \verb+HillClimbingTimetable+, which are simplified versions of the \gls{sa} classes. The \verb+HillClimbing+ and \verb+HillClimbingTimetable+'s methods and attributes can be seen in Figure \ref{fig:HillClimbing}.\\
\\
\begin{figure}[t!]
\centering
\begin{tikzpicture}
\begin{umlpackage}[x = 2, y = 0]{Heuristics Layer} 
\umlabstract[x = 0]{HillClimbing}
{
	\umlvirt{\#evaluation\_function : IEvaluationFunction}\\
}
{
	+Exec(solution : ISolution, milliseconds : long, type : int, \\ minimize : bool) : ISolution\\
	\umlvirt{\#GenerateNeighbor(solution : ISolution, type : int) : INeighbor}
}
\umlclass[x = 0, y = -5]{HillClimbingTimetable}
{
	\#evaluation\_function : IEvaluationFunction\\
	-neighbor\_selection\_timetable : NeighborSelectionTimetable\\
	+\umlstatic{type\_random : int}\\
	-random : Random\\
	+generated\_neighbors : int\\
	-total\_neighbor\_operators : int\\
}
{
	\#GenerateNeighbor(solution : ISolution, type : int) : INeighbor\\
	\#GenerateNeighbor(solution : Solution, type : int) : INeighbor\\
	-GenerateRandomNeighbor(solution : Solution) : INeighbor\\
}
\end{umlpackage}


\umlimpl[anchors=90 and -90]{HillClimbingTimetable}{HillClimbing} 
\end{tikzpicture}

\caption{Hill Climbing classes} 
\label{fig:HillClimbing}
\end{figure}

\section{Neighborhood Operators}
\label{sec:NeighborhoodOperators}

Neighborhood operators are applied to a solution, in order to create other valid solutions (neighbor solutions), but not necessarily feasible. In this context, the core of all operations are the relocation of the examinations.\\
\\
The implementation of neighborhood selection went through different approaches. Firstly, random selection was implemented. This approach always chooses a random operator to generate a new neighbor. Thereafter, guided approaches were implemented. The first one raised the probability of selecting one operator if this one generated a better neighbor solution. The probability of that operator is reduced in an equal amount if the operator generated a worse solution.\\
\\
The authors have implemented other variations of the first approach, where increasingly higher/lower probabilities of neighbor selection were defined based on the success/failure of the operator. Despite this, the random approach almost always showed better results compared to the guided approaches.\\
\\
The neighborhood operators, in this context, are all based on moving examinations in terms of period or room. This implementation uses six different neighborhood operators:
\\
\begin{itemize}
	\item \textit{Room Change} - An examination is randomly selected. After that, a room is randomly selected. If the assignment of the random examination to the random room, while maintaining the period, does not violate any hard constraints, that neighbor is returned. If not, the adjacent rooms are checked until one of them yields a feasible solution. If it reaches the limit of rooms and no feasible solution is found, no neighbor is returned;\\
	
	\item \textit{Period Change} - An examination is randomly selected. After that, a period is randomly selected. If the assignment of the examination to the period, while keeping the room, does not clash with any hard constraints, that neighbor is returned. If not, the adjacent periods are sequentially checked until one of them creates a feasible solution. If it reaches the limit of periods and no feasible solution is found, no neighbor is returned;\\
	
	\item \textit{Period \& Room Change} - An examination is randomly selected. After that, a room and period are randomly selected. If the assignment of the examination to the room and period does not clash with any hard constraints, that neighbor is returned. If not, the adjacent rooms are checked for each of the next periods, until one of them creates a feasible solution. If it reaches the limit of periods and rooms and no feasible solution is found, no neighbor is returned;\\
	
	\item \textit{Room Swap} - An examination is randomly selected. After that, a room is randomly selected. If the selected examination can be placed in that room, while keeping the period, then a \textit{Room Change} neighbor is returned instead. If not, if the swapping of the examination with any of the examinations presented in the room, keeping the same period, does not clash with any hard constraints, that neighbor is returned. If not, the examinations presented in the adjacent rooms are checked until a feasible solution is found (always checking first if a \textit{Room Change} can be returned instead). If it reaches the limit of rooms and no feasible solution is found, no neighbor is returned;\\
	
	\item \textit{Period Swap} -  An examination is randomly selected. After that, a period is randonly selected. If the selected examination can be placed in that period, while maintaining the room, then a \textit{Period Change} neighbor is returned instead. If not, if the swapping of the random examination with any of the examinations presented in the period, keeping the same room, does not clash with any hard constraints, that neighbor is returned. If not, the examinations presented in the adjacent periods are tested until a feasible solution is found (always testing first if a \textit{Period Change} can be returned instead). If it reaches the limit of periods and no feasible solution is found, no neighbor is returned;\\
	
	\item \textit{Period \& Room Swap} - An examination is randomly selected. After that, a period and room are randomly selected. If the selected examination can be placed in that period and room, then a \textit{Period \& Room Change} neighbor is returned instead. If not, if the swapping of the random examination with any of the examinations presented in the period and room does not clash with any hard constraints, that neighbor is returned. If not, the examinations presented in the adjacent periods and rooms are tested until a feasible solution is found (always testing first if a \textit{Period \& Room Change} can be returned instead). If it reaches the limit of periods and rooms and no feasible solution is found, no neighbor is returned.
\end{itemize}

\subsection{Implementation}

The original concept of neighbor solution is to have another solution apart from the current one, which is the result of applying the neighborhood operator to the current solution. In order to have an efficient implementation, the neighbor only keeps the changes introduced in the solution, and not the changed solution itself. With this design, there's no need to replicate the original solution and to apply the neighborhood operator to it in order to obtain the neighbor solution. The process of replacing the original solution with the neighbor, consists in applying to the current solution the movement registered in the neighbor.\\
\\
Every neighbor object must implement the interface \verb+INeighbor+, which exposes the methods \verb+Accept+, \verb+Reverse+ and a real value that represents the fitness of the neighbor (the fitness of the new solution if this neighbor is to be accepted). The \verb+Accept+ method  moves the current solution to the neighbor solution. The \verb+Reverse+ method undoes the operation, getting then back the old solution. The different neighbors and their methods are illustrated in Figure \ref{fig:Neighbors}.\\
\begin{figure}[p!]
\centering
\begin{tikzpicture}
\begin{umlpackage}[x = 2, y = 0]{Heuristics Layer} 

\umlclass[x = 0, y = 0]{SimulatedAnnealingTimetable}{}{}
\umlclass[x = 0, y = -4]{NeighborSelectionTimetable}
{
	-examinations : Examinations\\
	-rooms : Rooms\\
	-periods : Periods\\
	-feasibility\_tester : FeasibilityTester\\
	-evaluation\_function\_timetable : EvaluationFunctionTimetable\\
}
{
	+RoomSwap(solution : Solution) : INeighbor\\
	+PeriodSwap(solution : Solution) : INeighbor\\
	+PeriodRoomSwap(solution : Solution) : INeighbor\\
	+RoomChange(solution : Solution) : INeighbor\\
	+PeriodChange(solution : Solution) : INeighbor\\
	+PeriodRoomChange(solution : Solution) : INeighbor\\
}
\umlclass[x = 0, y = -9]{INeighbor}
{
	+fitness : int\\
}
{
	+Accept() : ISolution\\
	+Reverse() : ISolution
}
\umlclass[x = -3, y = -11]{PeriodChangeNeighbor}{}{}
\umlclass[x = -3, y = -13]{RoomChangeNeighbor}{}{}
\umlclass[x = -3, y = -15]{PeriodRoomChangeNeighbor}{}{}
\umlclass[x = 3, y = -11]{PeriodSwapNeighbor}{}{}
\umlclass[x = 3, y = -13]{RoomSwapNeighbor}{}{}
\umlclass[x = 3, y = -15]{PeriodRoomSwapNeighbor}{}{}


\end{umlpackage}



\umlimpl[geometry=-|, anchors=180 and -90]{PeriodChangeNeighbor}{INeighbor} 
\umlimpl[geometry=-|, anchors=180 and -90]{RoomChangeNeighbor}{INeighbor} 
\umlimpl[geometry=-|, anchors=180 and -90]{PeriodRoomChangeNeighbor}{INeighbor} 
\umlimpl[geometry=-|, anchors=-180 and -90]{PeriodSwapNeighbor}{INeighbor} 
\umlimpl[geometry=-|, anchors=-180 and -90]{RoomSwapNeighbor}{INeighbor} 
\umlimpl[geometry=-|, anchors=-180 and -90]{PeriodRoomSwapNeighbor}{INeighbor}
\umlinclude[anchors=-90 and 90, name=uses]{SimulatedAnnealingTimetable}{NeighborSelectionTimetable}
\umlinclude[anchors=-90 and 90, name=uses]{NeighborSelectionTimetable}{INeighbor} 
\end{tikzpicture}

\caption{Neighborhood selection and operators} 
\label{fig:Neighbors}
\end{figure}

\subsection{Statistics}
\label{sub:SAStatistics}
It is important to make sure that the algorithm works as planned. This includes the desired stochastic behavior, and all the neighbor operators must contribute positively to obtain better results.\\
\\
In this particular case, to make sure this heuristic is stochastic, we must guarantee that all the examinations are moved roughly the same number of times. Considering that some examinations are harder to move, these are moved less times than others, but the difference is not significant. A study was made to compare, in the same run, the number of rejected and accepted neighbors for each examination. The examinations are sorted in descending order by the number of conflicts. Figure \ref{fig:AvsRNeighbors} represents a color map in which the colors represent the number of times each examination was accepted (x = 1) and rejected (x = 2), for set 1. As can be seen, some examinations are not even selected to move, and so, have zero accepted and rejected results. In this particular set, only two lines have zero counters, as checked in the results file. These two examinations have \textit{exam\_coincidence} hard constraint and are only able to be in one room due to the number of students being too high. The \gls{sa} algorithm is not optimized to move more than one examination at the same time. This means that those two examinations can never be moved to another period, because the \gls{sa} can only move one examination at a time and these examinations can't be moved to another room, because they don't fit in other rooms.\\
\\
Other blue lines, which have values between 1000 and 1, are rare. This occurs not only because the examination is hard to move due to its conflicts, but may also have the \textit{exam\_coincidence} and a really short number of rooms in which that examination can fit. This problem creates a limitation in the \gls{sa} heuristic, preventing the \gls{sa} from scanning parts of the solution space, and eventually degrading the quality of the final result.\\
\\
\begin{figure}[t!]
\centering

\begin{tikzpicture}

	\begin{axis}[
		colorbar style={
		scaled y ticks = false,
		y tick label style={/pgf/number format/fixed,
			/pgf/number format/1000 sep = \thinspace 	% Optional if you want to
														% replace comma as the 1000
														% separator 
        }
		},
		width = \textwidth,
		xlabel = {Accepted (x=1) and rejected (x=2) neighbors},
		ylabel = {Exam indexes},
		enlarge x limits = true,	% The value true enlarges the lower 
									% and upper limit.
									% The value false uses tight axis limits
		enlarge y limits = true,
		colorbar,
		%colormap={}{ gray(0cm)=(1); gray(1cm)=(0);}, % Grey colorbar
		%x dir = reverse,
		y dir = reverse,
		%xmode = log,        % logarithmic x axis
		%xmin = 0, xmax = 9,
		% car92 has 543 exams
		%ymin = 0, ymax = 606, 
%		ytick = { 0, 100, 200, 300, 400, 500, 542},
		extra x ticks = {
1,
2,
3
}, extra x tick labels = {},
	    		extra tick style = { grid = major},
	    		width = \textwidth,
	    		%width = 17cm,
			%height = 11cm,
		]
		\addplot[surf, 
			shader = interp, % No facets
			point meta = explicit] 
			%table [z expr = 100, meta index = 2] {./yor83Cool1Eminus6.dat};
			table [z expr = 100, meta index = 2] {./SAResults6.dat};
\end{axis}

\end{tikzpicture}

\caption{Accepted and rejected neighbors for each examination in the Simulated Annealing.}
\label{fig:AvsRNeighbors} 
\end{figure}
\subsection{Neighborhood Operators Effect}
One of the most important aspects when dealing with the \gls{sa} is the choice of the neighbor operators. It is crucial that all the neighbor operators contribute positively. If a neighbor operator contributes negatively, it's better not to use it. M\"{u}ller proposed the first five operators~\cite{Mueller2009} \textit{Room Change}, \textit{Period Change}, \textit{Period \& Room Change}, \textit{Room Swap}, and \textit{Period Swap}. We add to the M\"{u}ller's set a sixth operator, the \textit{Period \& Room Swap} operator. In the sequel we present a study of the influence of this operator. For all 12 datasets, 20 runs were performed, computing the fitness average for each of the two cases. Table \ref{tab:NeighborsImprovementFactor} shows the improvement factor for using six neighbors instead of five. In most cases, it's worse compared to using the original five neighbor operators, and so, the 6th operator will not be used in this project's results. The results of using five operators also showed that more neighbors were generated and the percentage of feasible generated neighbors compared to the unfeasible, for each dataset, is also higher compared to using six neighbor operators.

\begin{table}[!t]
\centering
\caption{Improvement factor (percentage) between using five and six neighbor operators.}
\sisetup{table-alignment=center,detect-weight=true,detect-inline-weight=math}
\begin{tabular}{%
	S[table-figures-integer=3]%
	S[table-format=5.1]%
	S[table-format=5.1]%
	S[table-format=5.1]%
		S[table-format=5.1]%
    }

\toprule

\multicolumn{1}{c}{} & \multicolumn{1}{c}{5} &	\multicolumn{1}{c}{6} &	\multicolumn{1}{c}{Improvement}\\
\multicolumn{1}{c}{Dataset} & \multicolumn{1}{c}{Neighbors} &	\multicolumn{1}{c}{Neighbor}&	\multicolumn{1}{c}{Factor (\%)}\\
\multicolumn{1}{c}{} & \multicolumn{1}{c}{Operators} &	\multicolumn{1}{c}{Operators}&	\multicolumn{1}{c}{}\\
\midrule

1   &   5019  & 5055 & \textcolor{red}{-0.7}\\
2   &   478  & 523 & \textcolor{red}{-9.4} \\
3   &   14997  & 15228 & \textcolor{red}{-1.5} \\
4   &   \text{--}  & \text{--} & \text{--}\\
5   &   4950 & 4819 & \textcolor{green}{+1.5}\\
6   &   27680  & 27528 & \textcolor{green}{+0.5} \\
7   &   4799  & 4812 & \textcolor{red}{-0.3} \\
8   &   8551  & 8741 & \textcolor{red}{-2.2} \\
9   &   1141  & 1150 & \textcolor{red}{-0.8} \\
10  &   28219  & 25586 & \textcolor{green}{+9.3} \\
11  &   45344  & 45630 & \textcolor{red}{-0.6} \\
12  &   7222  & 7679 & \textcolor{red}{-6.3} \\

\bottomrule
$\sum$  &  148400   & 146751 & \textcolor{red}{-10.5}
\end{tabular}
\label{tab:NeighborsImprovementFactor}
\end{table}


\section{Fitness Computation}
\label{sec:FitnessComputation}

Fitness evaluation in timetable automation, due to its complexity, has a great influence in the algorithm performance. Hence, good performance of this step is required. As mentioned in the Subsection \ref{subsec:ToolsLayer}, this value is computed using the \verb+EvaluationFunction+ tool, which in a first approach, implies for generated neighbors, the recalculation of their fitness value. Tests were made to study this approach since the fitness results were not as good as expected. The tests showed that this approach was having poor performance, since most of the time was used to compute the fitness for each new neighbor generated solution.\\
\\
A new approach was implemented, which consists in computing the fitness incrementally. This means that for each new generated neighbor, a new fitness value is computed based on the current solution's fitness. This approach takes advantage of the fact that the operations applied to the current solution are simple and so the neighbor solutions are, in most part, equal to the current solution. Thus, the fitness computation is performed considering only the small changes between the current solution and the new generated neighbor solution.\\
\\
Tests were made to compare both approaches and, using the same parameters, for the first set it was possible to achieve equivalent results, 19 times faster. As a consequence if both approaches would use both the same parameters, and execution time, the new approach would have generated 19 times more neighbors, thus exploring the solution space with more detail.

\subsection{Implementation}

In order to compute the fitness of the neighbor solutions incrementally, a fitness function must be implemented depending on the type of neighbor. Considering that all neighbors have a reference to the solution they derive from, and the methods \verb+Accept+ and \verb+Reject+, it's possible to access the current solution and the neighbor generated solution (\verb+Accept+ will change the current solution and so the reference presented in this neighbor, replacing with the neighbor solution). \\
\\
The differences between the fitness values of the current solution and the new neighbor's depend on the type of neighbor created. For example, if a \verb+RoomSwapNeighbor+ is created, the changes will occur in the mixed durations constraints value of the periods and rooms of the swapped examinations. It is necessary to compute the impact (fitness values) of these conflicts in the current solution and subtract their values to the current fitness, proceeding with computing the same impact but now for the generated neighbor and to sum these values to the current fitness, thus obtaining the new neighbor's fitness value. The impact computing, mentioned above, is a simple rule that must be followed by all the soft constraints when computing the new neighbor's fitness incrementally.